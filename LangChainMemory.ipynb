{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bybG_XD5MYkD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LKDDxGbKMgB_",
        "outputId": "b8542d38-606f-4048-99ac-98b9d7c5c672"
      },
      "outputs": [],
      "source": [
        "api_key = os.getenv('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wrtwdZWtMjbs"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory, ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "jn2swzFJMw40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_15285/3909158301.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(api_key=api_key, temperature=0.0, model=mymodel)\n",
            "/tmp/ipykernel_15285/3909158301.py:3: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory()\n",
            "/tmp/ipykernel_15285/3909158301.py:4: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :meth:`~RunnableWithMessageHistory: https://python.langchain.com/v0.2/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html` instead.\n",
            "  conversation = ConversationChain(\n"
          ]
        }
      ],
      "source": [
        "mymodel = \"gpt-4\"\n",
        "llm = ChatOpenAI(api_key=api_key, temperature=0.0, model=mymodel)\n",
        "memory = ConversationBufferMemory()\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory = memory,\n",
        "    verbose=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWRzv7J0OCX3",
        "outputId": "d7320acb-b5e9-4cfd-cc59-d361fbd20e29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hello, how is it going?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Human: Hello, how is it going?\n",
            "AI: Hello! As an artificial intelligence, I don't have feelings or personal experiences, but I'm functioning as expected and ready to assist you. How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "conversation.predict(input=\"Hello, how is it going?\")\n",
        "print(memory.buffer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veKJumWHRCza",
        "outputId": "eaee09a4-5187-4f35-ac19-2abafb25463d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hello, how is it going?\n",
            "AI: Hello! As an artificial intelligence, I don't have feelings or personal experiences, but I'm functioning as expected and ready to assist you. How can I help you today?\n",
            "Human: What is my name?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Human: Hello, how is it going?\n",
            "AI: Hello! As an artificial intelligence, I don't have feelings or personal experiences, but I'm functioning as expected and ready to assist you. How can I help you today?\n",
            "Human: What is my name?\n",
            "AI: I'm sorry, but as an AI, I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality.\n"
          ]
        }
      ],
      "source": [
        "conversation.predict(input=\"What is my name?\")\n",
        "print(memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANvCBPRzRLDI",
        "outputId": "ac4acc95-31ef-4b4a-dc18-289c5da6b731"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': \"Human: Hello, how is it going?\\nAI: Hello! As an artificial intelligence, I don't have feelings or personal experiences, but I'm functioning as expected and ready to assist you. How can I help you today?\\nHuman: What is my name?\\nAI: I'm sorry, but as an AI, I don't have access to personal data about individuals unless it has been shared with me in the course of our conversation. I am designed to respect user privacy and confidentiality.\"}"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "iHMe4f_-SLOV",
        "outputId": "92209c13-19ab-4ae3-ac78-a5f3624471cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hello, how is it going?\n",
            "AI:\u001b[0m\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_15285/2375087300.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  new_memory = ConversationBufferWindowMemory(k=2)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hello, how is it going?\n",
            "AI: Hello! As an artificial intelligence, I don't have feelings or emotions, but I'm functioning as expected and ready to assist you. How can I help you today?\n",
            "Human: My Name is Nazli\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Hello, Nazli! It's nice to meet you. How can I assist you today?\""
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_memory = ConversationBufferWindowMemory(k=2)\n",
        "llm2 = ChatOpenAI(api_key=api_key, temperature=0.0, model=mymodel)\n",
        "new_conversation = ConversationChain(\n",
        "    llm=llm2,\n",
        "    memory = new_memory,\n",
        "    verbose=True\n",
        ")\n",
        "new_conversation.predict(input=\"Hello, how is it going?\")\n",
        "new_conversation.predict(input=\"My Name is Nazli\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "0ibUErhOVi28",
        "outputId": "0d1c96b4-79fb-45cc-f7c3-902e146d642e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hello, how is it going?\n",
            "AI: Hello! As an artificial intelligence, I don't have feelings or emotions, but I'm functioning as expected and ready to assist you. How can I help you today?\n",
            "Human: My Name is Nazli\n",
            "AI: Hello, Nazli! It's nice to meet you. How can I assist you today?\n",
            "Human: Today is sunny.\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: My Name is Nazli\n",
            "AI: Hello, Nazli! It's nice to meet you. How can I assist you today?\n",
            "Human: Today is sunny.\n",
            "AI: That's great to hear, Nazli! Sunny days can often boost people's moods and provide a great opportunity for outdoor activities. Do you have any plans to enjoy the weather?\n",
            "Human: How are you doing\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Today is sunny.\n",
            "AI: That's great to hear, Nazli! Sunny days can often boost people's moods and provide a great opportunity for outdoor activities. Do you have any plans to enjoy the weather?\n",
            "Human: How are you doing\n",
            "AI: As an artificial intelligence, I don't have feelings or emotions, but I'm functioning as expected and ready to assist you. How can I help you further, Nazli?\n",
            "Human: What is my name?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Your name is Nazli, as you've previously mentioned in our conversation.\""
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "new_conversation.predict(input=\"Today is sunny.\")\n",
        "new_conversation.predict(input=\"How are you doing\")\n",
        "new_conversation.predict(input=\"What is my name?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNRl_wOeVuYw",
        "outputId": "2fda469a-cbea-4590-e991-0c00eddef03c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': \"Human: How are you doing\\nAI: As an artificial intelligence, I don't have feelings or emotions, but I'm functioning as expected and ready to assist you. How can I help you further, Nazli?\\nHuman: What is my name?\\nAI: Your name is Nazli, as you've previously mentioned in our conversation.\"}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_memory.load_memory_variables({})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "llm_venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
